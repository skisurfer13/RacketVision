{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9519217,"sourceType":"datasetVersion","datasetId":5725210}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project: Tracknet along with Tennis Analysis","metadata":{}},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-09-30T20:58:47.733950Z","iopub.execute_input":"2024-09-30T20:58:47.734241Z","iopub.status.idle":"2024-09-30T21:00:06.505931Z","shell.execute_reply.started":"2024-09-30T20:58:47.734210Z","shell.execute_reply":"2024-09-30T21:00:06.504819Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: anyio==4.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.4.0)\nRequirement already satisfied: argon2-cffi==23.1.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (23.1.0)\nRequirement already satisfied: argon2-cffi-bindings==21.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (21.2.0)\nRequirement already satisfied: arrow==1.3.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: asttokens==2.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.4.1)\nRequirement already satisfied: async-lru==2.0.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.0.4)\nCollecting attrs==24.2.0 (from -r requirements.txt (line 7))\n  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting babel==2.16.0 (from -r requirements.txt (line 8))\n  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: beautifulsoup4==4.12.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.12.3)\nRequirement already satisfied: bleach==6.1.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (6.1.0)\nRequirement already satisfied: certifi==2024.7.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2024.7.4)\nCollecting cffi==1.17.0 (from -r requirements.txt (line 12))\n  Downloading cffi-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: charset-normalizer==3.3.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (3.3.2)\nRequirement already satisfied: colorama==0.4.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.4.6)\nRequirement already satisfied: comm==0.2.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.2.2)\nRequirement already satisfied: contourpy==1.2.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.2.1)\nRequirement already satisfied: cycler==0.12.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.12.1)\nCollecting debugpy==1.8.5 (from -r requirements.txt (line 18))\n  Downloading debugpy-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nCollecting decorator==4.4.2 (from -r requirements.txt (line 19))\n  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: defusedxml==0.7.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.7.1)\nCollecting exceptiongroup==1.2.2 (from -r requirements.txt (line 21))\n  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\nCollecting executing==2.1.0 (from -r requirements.txt (line 22))\n  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting fastjsonschema==2.20.0 (from -r requirements.txt (line 23))\n  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting filelock==3.15.4 (from -r requirements.txt (line 24))\n  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\nCollecting fonttools==4.53.1 (from -r requirements.txt (line 25))\n  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fqdn==1.5.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (1.5.1)\nRequirement already satisfied: fsspec==2024.6.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2024.6.1)\nRequirement already satisfied: h11==0.14.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.14.0)\nRequirement already satisfied: httpcore==1.0.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (1.0.5)\nCollecting httpx==0.27.2 (from -r requirements.txt (line 30))\n  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\nCollecting idna==3.8 (from -r requirements.txt (line 31))\n  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\nCollecting imageio==2.35.1 (from -r requirements.txt (line 32))\n  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\nCollecting imageio-ffmpeg==0.5.1 (from -r requirements.txt (line 33))\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nCollecting ipykernel==6.29.5 (from -r requirements.txt (line 34))\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nCollecting ipython==8.27.0 (from -r requirements.txt (line 35))\n  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\nCollecting ipywidgets==8.1.5 (from -r requirements.txt (line 36))\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: isoduration==20.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (20.11.0)\nRequirement already satisfied: jedi==0.19.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (0.19.1)\nRequirement already satisfied: jinja2==3.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (3.1.4)\nRequirement already satisfied: json5==0.9.25 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (0.9.25)\nCollecting jsonpointer==3.0.0 (from -r requirements.txt (line 41))\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nCollecting jsonschema==4.23.0 (from -r requirements.txt (line 42))\n  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: jsonschema-specifications==2023.12.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 43)) (2023.12.1)\nCollecting jupyter==1.1.1 (from -r requirements.txt (line 44))\n  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting jupyter-client==8.6.2 (from -r requirements.txt (line 45))\n  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: jupyter-console==6.6.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 46)) (6.6.3)\nRequirement already satisfied: jupyter-core==5.7.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 47)) (5.7.2)\nRequirement already satisfied: jupyter-events==0.10.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 48)) (0.10.0)\nCollecting jupyter-lsp==2.2.5 (from -r requirements.txt (line 49))\n  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\nCollecting jupyter-server==2.14.2 (from -r requirements.txt (line 50))\n  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: jupyter-server-terminals==0.5.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 51)) (0.5.3)\nCollecting jupyterlab==4.2.5 (from -r requirements.txt (line 52))\n  Downloading jupyterlab-4.2.5-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: jupyterlab-pygments==0.3.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 53)) (0.3.0)\nCollecting jupyterlab-server==2.27.3 (from -r requirements.txt (line 54))\n  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\nCollecting jupyterlab-widgets==3.0.13 (from -r requirements.txt (line 55))\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: kiwisolver==1.4.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 56)) (1.4.5)\nCollecting lapx==0.5.10 (from -r requirements.txt (line 57))\n  Downloading lapx-0.5.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: MarkupSafe==2.1.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 58)) (2.1.5)\nCollecting matplotlib==3.9.2 (from -r requirements.txt (line 59))\n  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: matplotlib-inline==0.1.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (0.1.7)\nCollecting mistune==3.0.2 (from -r requirements.txt (line 61))\n  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\nCollecting moviepy==1.0.3 (from -r requirements.txt (line 62))\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: mpmath==1.3.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (1.3.0)\nCollecting nbclient==0.10.0 (from -r requirements.txt (line 64))\n  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\nCollecting nbconvert==7.16.4 (from -r requirements.txt (line 65))\n  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: nbformat==5.10.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 66)) (5.10.4)\nRequirement already satisfied: nest-asyncio==1.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 67)) (1.6.0)\nRequirement already satisfied: networkx==3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 68)) (3.3)\nCollecting notebook==7.2.2 (from -r requirements.txt (line 69))\n  Downloading notebook-7.2.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: notebook-shim==0.2.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 70)) (0.2.4)\nCollecting numpy==1.23.0 (from -r requirements.txt (line 71))\n  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: opencv-python==4.10.0.84 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 72)) (4.10.0.84)\nRequirement already satisfied: overrides==7.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 73)) (7.7.0)\nCollecting packaging==24.1 (from -r requirements.txt (line 74))\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pandas==2.2.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 75)) (2.2.2)\nCollecting pandocfilters==1.5.1 (from -r requirements.txt (line 76))\n  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: parso==0.8.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 77)) (0.8.4)\nCollecting pillow==10.4.0 (from -r requirements.txt (line 78))\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting platformdirs==4.2.2 (from -r requirements.txt (line 79))\n  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\nCollecting proglog==0.1.10 (from -r requirements.txt (line 80))\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: prometheus-client==0.20.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 81)) (0.20.0)\nRequirement already satisfied: prompt-toolkit==3.0.47 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (3.0.47)\nCollecting psutil==6.0.0 (from -r requirements.txt (line 83))\n  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting pure-eval==0.2.3 (from -r requirements.txt (line 84))\n  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: py-cpuinfo==9.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 85)) (9.0.0)\nRequirement already satisfied: pycparser==2.22 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 86)) (2.22)\nRequirement already satisfied: pygments==2.18.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 87)) (2.18.0)\nCollecting pyparsing==3.1.4 (from -r requirements.txt (line 88))\n  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: python-dateutil==2.9.0.post0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 89)) (2.9.0.post0)\nRequirement already satisfied: python-json-logger==2.0.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 90)) (2.0.7)\nRequirement already satisfied: pytz==2024.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 91)) (2024.1)\n\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n\u001b[0mCollecting moviepy\n  Using cached moviepy-1.0.3.tar.gz (388 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.4)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.32.3)\nCollecting proglog<=1.0.0 (from moviepy)\n  Using cached proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\nDownloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110721 sha256=b8e9638ba58b7930eb91e192ee5d8ff676fae2aa3539b57975dae37a84769a8a\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\nSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\nCollecting ultralytics\n  Downloading ultralytics-8.3.1-py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.0)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.8-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.1-py3-none-any.whl (881 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.3/881.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.8-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.1 ultralytics-thop-2.0.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport constants\nimport pandas as pd\nfrom copy import deepcopy\nfrom moviepy.editor import *\nfrom mini_court import MiniCourt\nfrom detectors import BounceDetector\nfrom trackers import PlayerTracker,BallTracker\nfrom court_line_detector import CourtLineDetector\nfrom utils import (read_video, save_video, measure_distance,\n                   draw_player_stats, convert_pixel_distance_to_meters)\nfrom hawkeye import in_out_checker","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:00:06.508473Z","iopub.execute_input":"2024-09-30T21:00:06.509379Z","iopub.status.idle":"2024-09-30T21:00:16.815253Z","shell.execute_reply.started":"2024-09-30T21:00:06.509331Z","shell.execute_reply":"2024-09-30T21:00:16.814293Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setting Input-Output folder paths","metadata":{}},{"cell_type":"code","source":"input_video_folder_path = r\"input_videos\"\noutput_video_folder_path = r\"output_videos\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:00:16.816529Z","iopub.execute_input":"2024-09-30T21:00:16.817068Z","iopub.status.idle":"2024-09-30T21:00:16.821705Z","shell.execute_reply.started":"2024-09-30T21:00:16.817028Z","shell.execute_reply":"2024-09-30T21:00:16.820757Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## The main function","metadata":{}},{"cell_type":"code","source":"def main():\n    # Getting all videos from the input directory\n    input_videos = glob.glob(f\"{input_video_folder_path}/*\")\n    if len(input_videos) == 0:\n        print(\"No video is present in the input folder\")\n    else:    \n        for video_path in input_videos:\n            # Read Video\n            input_video_path = f\"{video_path}\"\n            clip = VideoFileClip(f\"{video_path}\")\n            fps = int(clip.fps)\n            video_frames = read_video(input_video_path, fps)\n            print(\"No. of video_frames:\",len(video_frames))\n            # Extracting audio\n            audioclip = AudioFileClip(input_video_path)\n            new_audioclip = CompositeAudioClip([audioclip])\n            \n            # Detect Players, Ball and Bounce\n            player_tracker = PlayerTracker(model_path='models/yolov8x.pt')\n            ball_tracker = BallTracker(model_path='models/tracknet_model_best.pt') \n            bounce_detector = BounceDetector(model_path='models/ctb_regr_bounce.cbm')\n        \n            player_detections = player_tracker.detect_frames(video_frames,\n                                                               read_from_stub=False,\n                                           stub_path=\"tracker_stubs/player_detections.pkl\"\n                                        )\n            ball_detections = ball_tracker.detect_frames(video_frames, \n                                                         read_from_stub=False,\n                                        stub_path=\"tracker_stubs/ball_detections.pkl\"\n                                        )\n            print(\"Ball detections:\",len(ball_detections))\n            ball_detections = ball_tracker.interpolate_ball_positions(ball_detections)\n            bounce_detection_frames = bounce_detector.detect_bounce_positions(ball_detections)\n\n            # Court Line Detector model\n            court_model_path = \"models/keypoints_model_trained.pth\"\n            court_line_detector = CourtLineDetector(court_model_path)\n            court_keypoints = court_line_detector.predict(video_frames[0])\n        \n            # choose players\n            player_detections = player_tracker.choose_and_filter_players(court_keypoints, player_detections)\n        \n            # MiniCourt\n            mini_court = MiniCourt(video_frames[0]) \n        \n            # Detect ball shots\n            ball_shot_frames= ball_tracker.get_ball_shot_frames(ball_detections)\n            # Convert positions to mini court positions\n            player_mini_court_detections, ball_mini_court_detections = mini_court.convert_bounding_boxes_to_mini_court_coordinates(player_detections, \n                                                                                                                  ball_detections,\n                                                                                                                  court_keypoints)\n            \n            player_depth_data = [{\n                'frame_num':0,\n                'player_1_last_shot_depth':0,\n                'player_1_total_shot_depth':0,\n                'player_1_total_bounce':0.000001,\n                'player_1_hawkeye':0,\n                'player_2_last_shot_depth':0,\n                'player_2_total_shot_depth':0,\n                'player_2_total_bounce':0.000001,\n                'player_2_hawkeye':0\n            } ]\n\n            for bounce_shot_ind in range(len(bounce_detection_frames)):\n                # Get distance covered by the ball\n                bounce_frame = bounce_detection_frames[bounce_shot_ind]\n                ball_player1_distance = measure_distance(player_mini_court_detections[bounce_frame][1],\n                                                                ball_mini_court_detections[bounce_frame][1])\n                \n                ball_player2_distance = measure_distance(player_mini_court_detections[bounce_frame][2],\n                                                                ball_mini_court_detections[bounce_frame][1])\n                \n                if ball_player1_distance > ball_player2_distance:\n                    player_depth_shot_id = 1\n                else:\n                    player_depth_shot_id = 2\n                \n                tennis_net_y = mini_court.get_tennis_net_y_point()\n                depth_of_shot = abs(tennis_net_y - ball_mini_court_detections[bounce_frame][1][1])\n\n                depth_meters = convert_pixel_distance_to_meters( depth_of_shot,\n                                                                constants.DOUBLE_LINE_WIDTH,\n                                                                mini_court.get_width_of_mini_court()\n                                                                )\n                # For Hawk eye 0:IN, 1:OUT\n                mini_court_keypoints_hwk = mini_court.get_court_drawing_keypoints()\n                hawk_eye = in_out_checker(mini_court_keypoints_hwk, ball_mini_court_detections[bounce_frame][1])\n\n                current_player_depth = deepcopy(player_depth_data[-1])\n                current_player_depth['frame_num'] = bounce_frame\n                current_player_depth[f'player_{player_depth_shot_id}_total_bounce'] += 1\n                current_player_depth[f'player_{player_depth_shot_id}_last_shot_depth'] = depth_meters\n                current_player_depth[f'player_{player_depth_shot_id}_total_shot_depth'] += depth_meters\n                current_player_depth[f'player_{player_depth_shot_id}_hawkeye'] = hawk_eye\n                player_depth_data.append(current_player_depth)\n            player_depth_data_df = pd.DataFrame(player_depth_data)               \n\n\n            player_stats_data = [{\n                'frame_num':0,\n                'player_1_number_of_shots':0.000001,\n                'player_1_total_shot_speed':0,\n                'player_1_last_shot_speed':0,\n                'player_1_total_player_speed':0,\n                'player_1_last_player_speed':0,\n        \n                'player_2_number_of_shots':0.000001,\n                'player_2_total_shot_speed':0,\n                'player_2_last_shot_speed':0,\n                'player_2_total_player_speed':0,\n                'player_2_last_player_speed':0,\n            } ]\n            \n            for ball_shot_ind in range(len(ball_shot_frames)-1):\n                try:\n                    start_frame = ball_shot_frames[ball_shot_ind]\n                    end_frame = ball_shot_frames[ball_shot_ind+1]\n                    ball_shot_time_in_seconds = (end_frame-start_frame)/fps # 24fps\n        \n                    # Get distance covered by the ball\n                    distance_covered_by_ball_pixels = measure_distance(ball_mini_court_detections[start_frame][1],\n                                                                    ball_mini_court_detections[end_frame][1])\n                    distance_covered_by_ball_meters = convert_pixel_distance_to_meters( distance_covered_by_ball_pixels,\n                                                                                    constants.DOUBLE_LINE_WIDTH,\n                                                                                    mini_court.get_width_of_mini_court()\n                                                                                    ) \n        \n                    # Speed of the ball shot in km/h\n                    speed_of_ball_shot = distance_covered_by_ball_meters/ball_shot_time_in_seconds * 3.6\n        \n                    # player who the ball\n                    player_positions = player_mini_court_detections[start_frame]\n                    player_shot_ball = min( player_positions.keys(), key=lambda player_id: measure_distance(player_positions[player_id],\n                                                                                                            ball_mini_court_detections[start_frame][1]))\n        \n                    # opponent player speed\n                    opponent_player_id = 1 if player_shot_ball == 2 else 2\n                    distance_covered_by_opponent_pixels = measure_distance(player_mini_court_detections[start_frame][opponent_player_id],\n                                                                            player_mini_court_detections[end_frame][opponent_player_id])\n                    distance_covered_by_opponent_meters = convert_pixel_distance_to_meters( distance_covered_by_opponent_pixels,\n                                                                                    constants.DOUBLE_LINE_WIDTH,\n                                                                                    mini_court.get_width_of_mini_court()\n                                                                                    ) \n        \n                    speed_of_opponent = distance_covered_by_opponent_meters/ball_shot_time_in_seconds * 3.6\n        \n                    current_player_stats= deepcopy(player_stats_data[-1])\n                    current_player_stats['frame_num'] = start_frame\n                    current_player_stats[f'player_{player_shot_ball}_number_of_shots'] += 1\n                    current_player_stats[f'player_{player_shot_ball}_total_shot_speed'] += speed_of_ball_shot\n                    current_player_stats[f'player_{player_shot_ball}_last_shot_speed'] = speed_of_ball_shot\n        \n                    current_player_stats[f'player_{opponent_player_id}_total_player_speed'] += speed_of_opponent\n                    current_player_stats[f'player_{opponent_player_id}_last_player_speed'] = speed_of_opponent\n        \n                    player_stats_data.append(current_player_stats)\n                except:\n                    continue\n            \n            player_stats_data_df = pd.DataFrame(player_stats_data)\n            frames_df = pd.DataFrame({'frame_num': list(range(len(video_frames)))})\n            player_stats_data_df = pd.merge(frames_df, player_stats_data_df, on='frame_num', how='left')\n            player_stats_data_df = pd.merge(player_stats_data_df, player_depth_data_df, on='frame_num', how='left' )\n            player_stats_data_df = player_stats_data_df.ffill()\n\n            player_stats_data_df['player_1_average_shot_speed'] = player_stats_data_df['player_1_total_shot_speed']/player_stats_data_df['player_1_number_of_shots']\n            player_stats_data_df['player_2_average_shot_speed'] = player_stats_data_df['player_2_total_shot_speed']/player_stats_data_df['player_2_number_of_shots']\n            player_stats_data_df['player_1_average_player_speed'] = player_stats_data_df['player_1_total_player_speed']/player_stats_data_df['player_2_number_of_shots']\n            player_stats_data_df['player_2_average_player_speed'] = player_stats_data_df['player_2_total_player_speed']/player_stats_data_df['player_1_number_of_shots']\n            \n            player_stats_data_df['player_1_average_shot_depth'] = player_stats_data_df['player_1_total_shot_depth']/player_stats_data_df['player_1_total_bounce']\n            player_stats_data_df['player_2_average_shot_depth'] = player_stats_data_df['player_2_total_shot_depth']/player_stats_data_df['player_2_total_bounce']\n\n        \n        \n            # Draw output\n            # Draw Player Bounding Boxes\n            output_video_frames= player_tracker.draw_bboxes(video_frames, player_detections)\n            output_video_frames= ball_tracker.draw_bboxes(output_video_frames, ball_detections)\n            \n            # Draw court Keypoints\n            output_video_frames  = court_line_detector.draw_keypoints_on_video(output_video_frames, court_keypoints)\n        \n            # # Draw Mini Court\n            output_video_frames = mini_court.draw_mini_court(output_video_frames)\n            output_video_frames = mini_court.draw_points_on_mini_court(output_video_frames,player_mini_court_detections)\n            output_video_frames = mini_court.draw_points_on_mini_court(output_video_frames,ball_mini_court_detections, color=(0,255,255))    \n        \n            # Draw Player Stats\n            output_video_frames = draw_player_stats(output_video_frames,player_stats_data_df)\n        \n            ## Draw frame number on top left corner\n            for i, frame in enumerate(output_video_frames):\n                cv2.putText(frame, f\"Frame: {i}\",(10,30),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n        \n            # save_video\n            input_name = os.path.basename(f\"{video_path}\")\n            \n            save_video(output_video_frames, f\"tmp\\output_{input_name}.avi\", fps)\n\n            # Printing average stats\n            print(f\"---------------For video {input_name}---------------\")\n            print(\"player_1_average_shot_speed:\",player_stats_data_df['player_1_average_shot_speed'].iloc[-1])\n            print(\"player_2_average_shot_speed:\",player_stats_data_df['player_2_average_shot_speed'].iloc[-1])\n            print(\"player_1_average_player_speed:\",player_stats_data_df['player_1_average_player_speed'].iloc[-1])\n            print(\"player_2_average_player_speed:\",player_stats_data_df['player_2_average_player_speed'].iloc[-1])\n            print(\"player_1_average_shot_depth:\",player_stats_data_df['player_1_average_shot_depth'].iloc[-1])\n            print(\"player_2_average_shot_depth:\",player_stats_data_df['player_2_average_shot_depth'].iloc[-1])\n            \n            # avi to mp4\n            video_clip_final = VideoFileClip(f\"tmp\\output_{input_name}.avi\")\n            path, file_name = os.path.split(f\"{output_video_folder_path}/output_{input_name}.avi\")\n            output_name = os.path.join(path, os.path.splitext(file_name)[0])\n\n            # adding audio\n            video_clip_final.audio = new_audioclip\n            video_clip_final.write_videofile(output_name)\n            \n            # Deleting redundant files\n            files = glob.glob('tmp/*')\n            for f in files:\n                os.remove(f)\n            ","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:00:16.824446Z","iopub.execute_input":"2024-09-30T21:00:16.824777Z","iopub.status.idle":"2024-09-30T21:00:16.867294Z","shell.execute_reply.started":"2024-09-30T21:00:16.824742Z","shell.execute_reply":"2024-09-30T21:00:16.866183Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:00:16.868648Z","iopub.execute_input":"2024-09-30T21:00:16.869010Z","iopub.status.idle":"2024-09-30T21:14:16.953423Z","shell.execute_reply.started":"2024-09-30T21:00:16.868974Z","shell.execute_reply":"2024-09-30T21:14:16.952386Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"dim[0]= 1920\nvid cap\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\nCollecting lapx>=0.5.2\n  Downloading lapx-0.5.10.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from lapx>=0.5.2) (1.26.4)\nDownloading lapx-0.5.10.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lapx\nSuccessfully installed lapx-0.5.10.post1\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 12.5s, installed 1 package: ['lapx>=0.5.2']\n\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n0: 384x640 10 persons, 114.2ms\nSpeed: 13.7ms preprocess, 114.2ms inference, 383.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 10 persons, 53.7ms\nSpeed: 2.3ms preprocess, 53.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 10 persons, 53.7ms\nSpeed: 2.1ms preprocess, 53.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 10 persons, 51.7ms\nSpeed: 2.1ms preprocess, 51.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 10 persons, 48.6ms\nSpeed: 1.8ms preprocess, 48.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 48.5ms\nSpeed: 2.0ms preprocess, 48.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 35.6ms\nSpeed: 2.2ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 35.2ms\nSpeed: 2.9ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 34.9ms\nSpeed: 2.1ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 3.0ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 1.9ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.5ms\nSpeed: 3.4ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 1.9ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.0ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.9ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.0ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.8ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.3ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 2.1ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.2ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.2ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 1.9ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.0ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.1ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.0ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.9ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 3.1ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.9ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.0ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.0ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 3.0ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.8ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.9ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.1ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 3.0ms preprocess, 29.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.9ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.2ms\nSpeed: 2.9ms preprocess, 30.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.8ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 3.0ms preprocess, 29.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.9ms preprocess, 30.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.0ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.8ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.8ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.1ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.0ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.3ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.2ms\nSpeed: 1.9ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.0ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.0ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.1ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.8ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.8ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.8ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.3ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 1.9ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.2ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.0ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.0ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 1.9ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.2ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.3ms\nSpeed: 2.0ms preprocess, 30.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 1.9ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.9ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.1ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.3ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 3.1ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 1.9ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.0ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.3ms\nSpeed: 2.1ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.1ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 1.9ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.3ms\nSpeed: 3.0ms preprocess, 30.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 1.9ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.1ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.5ms\nSpeed: 2.5ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.8ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.5ms\nSpeed: 3.4ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 3.3ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 3.0ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 2.3ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.2ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.1ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.2ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 2.2ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.3ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.4ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 3.0ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.5ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.2ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.0ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.4ms\nSpeed: 3.0ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.0ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 3.1ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.2ms\nSpeed: 3.0ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.1ms preprocess, 29.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.8ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.9ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 2.9ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.1ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.8ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.9ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 3.1ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 2.9ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 3.0ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.6ms\nSpeed: 3.0ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.0ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.0ms\nSpeed: 2.1ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 30.1ms\nSpeed: 2.8ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.1ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.8ms\nSpeed: 2.8ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 1.9ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.9ms\nSpeed: 3.0ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 2.8ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 29.7ms\nSpeed: 3.0ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.1ms\nSpeed: 2.8ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.8ms\nSpeed: 1.9ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.8ms\nSpeed: 3.1ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.7ms\nSpeed: 2.8ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.1ms\nSpeed: 2.8ms preprocess, 29.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.7ms\nSpeed: 2.1ms preprocess, 29.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.2ms\nSpeed: 2.0ms preprocess, 30.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.2ms\nSpeed: 3.4ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.3ms\nSpeed: 2.0ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.6ms\nSpeed: 1.9ms preprocess, 30.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.4ms\nSpeed: 2.0ms preprocess, 30.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.9ms\nSpeed: 2.0ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.0ms\nSpeed: 1.9ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.9ms\nSpeed: 2.9ms preprocess, 29.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.8ms\nSpeed: 2.0ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 29.8ms\nSpeed: 2.8ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 30.0ms\nSpeed: 1.9ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 129/129 [13:24<00:00,  6.24s/it]\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 181MB/s] \n","output_type":"stream"},{"name":"stdout","text":"---------------For video resi_inp_vid.mp4---------------\nplayer_1_average_shot_speed: 0.0\nplayer_2_average_shot_speed: 65.92566642694032\nplayer_1_average_player_speed: 8.80664733617989\nplayer_2_average_player_speed: 0.0\nplayer_1_average_shot_depth: 0.0\nplayer_2_average_shot_depth: 7.127078901216254\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}